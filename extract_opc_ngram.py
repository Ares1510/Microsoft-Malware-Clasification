import os
import shutil
import numpy as np
import pandas as pd
import re
import glob
from sklearn.feature_extraction.text import CountVectorizer
from tqdm import tqdm
import concurrent.futures

#Top opcodes
opcodes = ['jmp', 'mov', 'retf', 'push', 'pop', 'xor', 'retn', 'nop', 'sub', 
           'inc', 'dec', 'add', 'imul', 'xchg', 'or', 'shr', 'cmp', 'call', 
           'shl', 'ror', 'rol', 'jnb', 'jz', 'rtn','lea','movzx']

opcodes_bi = []
for i, value in enumerate(opcodes):
    for j in range(len(opcodes)):
        opcodes_bi.append(value + ' ' + opcodes[j])

opcodes_tri = []
for i, value in enumerate(opcodes):
    for j in range(len(opcodes)):
        for k in range(len(opcodes)):
            opcodes_tri.append(value + ' ' + opcodes[j] + ' ' + opcodes[k])

opc_vocab = opcodes + opcodes_bi + opcodes_tri


#Extracting opcode uni, bi, trigrams            
def opcode_ngrams(group):
    with open(group + '/opc_ngrams.csv', 'w') as f:
        f.write('file,')
        for word in opc_vocab:
            if word != opc_vocab[-1]:
                f.write(word + ',')
            else:
                f.write(word + '\n')
        vectorizer = CountVectorizer(input='filename', vocabulary=opc_vocab, ngram_range=(1, 3))
        files = glob.glob(group + '/*_opc.txt')
        arr = vectorizer.transform(files).toarray()
        for index, file in enumerate(tqdm(files)):
            f.write(file.split('/')[3][:-8] + ',')
            for pos, value in enumerate(arr[index]):
                if pos != len(opc_vocab)-1:
                    f.write(str(value) + ',')
                else:
                    f.write(str(value))
            f.write('\n')

def join_csv(x):
    files = glob.glob(x + '/asm/*/opc*.csv')
    dfs = []
    for file in files:
        dfs.append(pd.read_csv(file))
    final = pd.concat(dfs)
    final.to_csv(x + '/opcodes_ngrams.csv', index=False)
    for file in files:
        os.remove(file)
        
def main():
    groups = glob.glob('train/asm/*')
    with concurrent.futures.ProcessPoolExecutor(max_workers=16) as executor:
        executor.map(opcode_ngrams, groups)
    join_csv('train')
    
    groups = glob.glob('test/asm/*')
    with concurrent.futures.ProcessPoolExecutor(max_workers=16) as executor:
        executor.map(opcode_ngrams, groups)
    join_csv('test')

if __name__ == "__main__":
    main()
import os
import shutil
import numpy as np
import pandas as pd
import re
import glob
from sklearn.feature_extraction.text import CountVectorizer
from tqdm import tqdm
import concurrent.futures

#Top headers 
headers = ['.2', '.3', '.CRT', '.Lax503', '.Much', '.Pav', '.RDATA', '.Racy',
             '.Re82', '.Reel', '.Sty', '.Tls', '.adata', '.bas', '.bas0', '.brick',
             '.bss', '.code', '.cud', '.data', '.data1', '.edata', '.gnu_deb', '.hdata',
             '.icode', '.idata', '.laor', '.ndata', '.orpc', '.pdata', '.rata', '.rdat',
             '.rdata', '.reloc', '.rsrc', '.sdbid', '.sforce3', '.text', '.text1', '.tls',
             '.xdata', '.zenc', 'BSS', 'CODE', 'DATA', 'GAP', 'HEADER',
             'JFsX_', 'UPX0', 'UPX1', 'Xd_?_mf', '_0', '_1', '_2', '_3',
             '_4', '_5', 'bss', 'code', 'seg000', 'seg001', 'seg002', 'seg003',
             'seg004']

#Extracting header unigrams
def header_ngrams(group):
    with open(group + '/hed_ngrams.csv', 'w') as f:
        f.write('file,')
        for word in headers:
            if word != headers[-1]:
                f.write(word + ',')
            else:
                f.write(word + '\n')
        vectorizer = CountVectorizer(input='filename', vocabulary=headers, ngram_range=(1, 1), tokenizer=str.split)
        files = glob.glob(group + '/*_hed.txt')
        arr = vectorizer.transform(files).toarray()
        for index, file in enumerate(tqdm(files)):
            f.write(file.split('/')[3][:-8] + ',')
            for pos, value in enumerate(arr[index]):
                if pos != len(headers)-1:
                    f.write(str(value) + ',')
                else:
                    f.write(str(value))
            f.write('\n')


def join_csv(x):
    files = glob.glob(x + '/asm/*/hed*.csv')
    dfs = []
    for file in files:
        dfs.append(pd.read_csv(file))
    final = pd.concat(dfs)
    final.to_csv(x + '/header_ngrams.csv', index=False)
    for file in files:
        os.remove(file)
        


def main():
    groups = glob.glob('train/asm/*')
    with concurrent.futures.ProcessPoolExecutor(max_workers=16) as executor:
        executor.map(header_ngrams, groups)
    join_csv('train')
    
    groups = glob.glob('test/asm/*')
    with concurrent.futures.ProcessPoolExecutor(max_workers=16) as executor:
        executor.map(header_ngrams, groups)
    join_csv('test')

if __name__ == "__main__":
    main()